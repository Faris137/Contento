{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This note is consolidating the main components for the model:\n",
    "# 1- Loading the Images.\n",
    "# 2- Features Engineering, extracting SURF features.\n",
    "# 3- The bag of words visual method implemtation.\n",
    "# 4- Training the model.\n",
    "# 5- Creating the persistent model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import mahotas as mh\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from glob import glob\n",
    "import cv2\n",
    "from mahotas.features import surf\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy\n",
    "from sklearn import preprocessing, cross_validation, neighbors,datasets, svm\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SURF descriptors: 94080\n",
      "SURFcluster persistent model Generated\n",
      "features are saved into file Featurset\n",
      "Labels Generated into file Labels\n"
     ]
    }
   ],
   "source": [
    "images = glob('Dataset/*.jpg')\n",
    "descriptors = []\n",
    "for im in images:\n",
    "    im = mh.imread(im, as_grey=True)\n",
    "    im = im.astype(np.uint8)\n",
    "    descriptors.append(surf.dense(im, spacing=16))\n",
    "\n",
    "alldescriptors = []\n",
    "for im in images:\n",
    "    im = mh.imread(im, as_grey=True)\n",
    "    im = im.astype(np.uint8)\n",
    "    alldescriptors.append(surf.dense(im, spacing=16))\n",
    "# get all descriptors into a single array\n",
    "concatenated = np.concatenate(alldescriptors)\n",
    "print('Number of SURF descriptors: {}'.format(len(concatenated)))\n",
    "\n",
    "#use only every 64th vector\n",
    "concatenated = concatenated[::61]\n",
    "k = 256 #The number of cetroids must not be greater than the number of images,\n",
    "#usually the number of cetroids should be kept in the order 32,64,128,256,512...\n",
    "km = KMeans(k) #using the k-means to cluster the SURF descriptors\n",
    "km.fit(concatenated)\n",
    "\n",
    "joblib.dump(km, 'SURFcluster.pkl')\n",
    "print \"SURFcluster persistent model Generated\"\n",
    "    \n",
    "sfeatures = []\n",
    "for d in alldescriptors:\n",
    "    c = km.predict(d)\n",
    "    sfeatures.append(np.array([np.sum(c == ci) for ci in range(k)]))\n",
    "sfeatures = np.array(sfeatures, dtype=float)\n",
    "features = np.save(\"Featurset\", sfeatures)\n",
    "print \"features are saved into file Featurset\"\n",
    "\n",
    "a = np.zeros(240)\n",
    "b = np.ones(240)\n",
    "c = np.concatenate((a,b), axis =0)\n",
    "labels = np.save(\"Labels\", c)\n",
    "print \"Labels Generated into file Labels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Accuracy in the training data:  99.7023809524 %\n",
      "Accuracy in the test data 99.7023809524 %\n",
      "\n",
      "Training classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      0.99      1.00       167\n",
      "        1.0       0.99      1.00      1.00       169\n",
      "\n",
      "avg / total       1.00      1.00      1.00       336\n",
      "\n",
      "\n",
      " Confusion matrix of training \n",
      "[[166   1]\n",
      " [  0 169]]\n",
      "\n",
      "Testing classification report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.79      0.81      0.80        73\n",
      "        1.0       0.80      0.77      0.79        71\n",
      "\n",
      "avg / total       0.79      0.79      0.79       144\n",
      "\n",
      "\n",
      "Confusion matrix of the testing\n",
      "[[59 14]\n",
      " [16 55]]\n",
      "\n",
      "Area Under the ROC curve:  0.87690526722\n",
      "Mean True Positive rate (testing):  0.715689485752\n",
      "Mean False Positive rate (testing):  0.264733991717\n"
     ]
    }
   ],
   "source": [
    "#X = np.load(\"Featurset.npy\")\n",
    "#y = np.load(\"Labels.npy\")\n",
    "\n",
    "X = sfeatures\n",
    "y = c\n",
    "\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "#scaling\n",
    "scaler = StandardScaler()\n",
    "#scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Fit only on training data\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "# apply same transformation to test data\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(probability = True)\n",
    "#clf = MLPClassifier(solver='sgd', alpha=1e-5, hidden_layer_sizes=(10, 5, 20), random_state=2, learning_rate_init=0.05, max_iter=10000)\n",
    "print clf\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "Accuracy = clf.score(X_train, y_train)\n",
    "print \"Accuracy in the training data: \", Accuracy*100, \"%\"\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "print \"Accuracy in the test data\", Accuracy*100, \"%\"\n",
    "\n",
    "y_pred = clf.predict(X_train)\n",
    "print '\\nTraining classification report\\n', classification_report(y_train, y_pred)\n",
    "print \"\\n Confusion matrix of training \\n\", confusion_matrix(y_train, y_pred)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print '\\nTesting classification report\\n', classification_report(y_test, y_pred)\n",
    "print \"\\nConfusion matrix of the testing\\n\", confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "probas = clf.fit(X_train, y_train).predict_proba(X_test)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, probas[:, 1])\n",
    "mean_tpr = 0.0\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "mean_tpr += interp(mean_fpr, fpr, tpr)\n",
    "mean_tpr[0] = 0.0\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print \"\\nArea Under the ROC curve: \", roc_auc\n",
    "\n",
    "meanTP = 0\n",
    "for t in tpr:\n",
    "    meanTP += t\n",
    "print \"Mean True Positive rate (testing): \", meanTP/len(tpr)\n",
    "\n",
    "meanFP = 0\n",
    "for t in fpr:\n",
    "    meanFP += t\n",
    "print \"Mean False Positive rate (testing): \", meanFP/len(fpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SatisfactionDetector persistent model Generated\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(clf, 'SatisfactionDetector.pkl')\n",
    "print \"SatisfactionDetector persistent model Generated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n",
      "[[ 0.81  0.19]\n",
      " [ 0.23  0.77]]\n"
     ]
    }
   ],
   "source": [
    "class_names = ['Satisfied', 'UnSatisfied']\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=True,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "# Compute confusion matrix\n",
    "y_pred = clf.predict(X_test)\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
